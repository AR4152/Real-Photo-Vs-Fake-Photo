{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-11T16:00:59.385888Z",
     "iopub.status.busy": "2021-06-11T16:00:59.385576Z",
     "iopub.status.idle": "2021-06-11T16:00:59.39241Z",
     "shell.execute_reply": "2021-06-11T16:00:59.391458Z",
     "shell.execute_reply.started": "2021-06-11T16:00:59.385858Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import datasets, models, transforms\n",
    "from torchvision.models import resnet18\n",
    "\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data set\n",
    "\n",
    "Before we deal with the models, we need to understand how to upload the data set. Let's write a torch class for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-11T16:01:00.23679Z",
     "iopub.status.busy": "2021-06-11T16:01:00.236466Z",
     "iopub.status.idle": "2021-06-11T16:01:00.245796Z",
     "shell.execute_reply": "2021-06-11T16:01:00.244831Z",
     "shell.execute_reply.started": "2021-06-11T16:01:00.236758Z"
    }
   },
   "outputs": [],
   "source": [
    "class FaceDataset(Dataset):\n",
    "    def __init__(self, data_df, transform=None):\n",
    "        \"\"\"\n",
    "        Now we initialize the class by sending it a table \n",
    "        with image data \n",
    "        \"\"\"\n",
    "        self.data_df = data_df\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # we get the name of the image and its label\n",
    "        image_name, label = self.data_df.iloc[idx]['name'], self.data_df.iloc[idx]['label']\n",
    "        \n",
    "        # read the image\n",
    "        image = cv2.imread(f\"../input/data256faces/data256/train/{image_name}\")\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        image = Image.fromarray(image)\n",
    "        \n",
    "        # transform it, if necessary\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return image, torch.tensor(label).long()\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-11T16:01:00.70791Z",
     "iopub.status.busy": "2021-06-11T16:01:00.707638Z",
     "iopub.status.idle": "2021-06-11T16:01:00.713571Z",
     "shell.execute_reply": "2021-06-11T16:01:00.712607Z",
     "shell.execute_reply.started": "2021-06-11T16:01:00.707872Z"
    }
   },
   "outputs": [],
   "source": [
    "we set the image transformation \n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize(224),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                          std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "valid_transform = transforms.Compose([\n",
    "    transforms.Resize(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                          std=[0.229, 0.224, 0.225]),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-11T16:01:01.111953Z",
     "iopub.status.busy": "2021-06-11T16:01:01.11166Z",
     "iopub.status.idle": "2021-06-11T16:01:01.139549Z",
     "shell.execute_reply": "2021-06-11T16:01:01.138764Z",
     "shell.execute_reply.started": "2021-06-11T16:01:01.111926Z"
    }
   },
   "outputs": [],
   "source": [
    "# read the data set\n",
    "\n",
    "data_df = pd.read_csv(\"../input/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-11T16:01:01.498653Z",
     "iopub.status.busy": "2021-06-11T16:01:01.498393Z",
     "iopub.status.idle": "2021-06-11T16:01:02.494306Z",
     "shell.execute_reply": "2021-06-11T16:01:02.493358Z",
     "shell.execute_reply.started": "2021-06-11T16:01:01.498627Z"
    }
   },
   "outputs": [],
   "source": [
    "# let's look at the images\n",
    "\n",
    "fig, axs = plt.subplots(2, 4, figsize=(16,8))\n",
    "fig.suptitle(f'True images {\" \"*105} Fake images', fontsize=14)\n",
    "\n",
    "for i, name in zip(range(4), data_df[ data_df['label'] == 0 ].sample(4, random_state=42)['name']):\n",
    "    axs[i // 2, (i % 2)].imshow(plt.imread(f\"../input/data256faces/data256/train/{name}\"))\n",
    "    axs[i // 2, (i % 2)].axis('off')\n",
    "\n",
    "for i, name in zip(range(4), data_df[ data_df['label'] == 1 ].sample(4, random_state=42)['name']):\n",
    "    axs[i // 2, (i % 2)+2].imshow(plt.imread(f\"../input/data256faces/data256/train/{name}\"))\n",
    "    axs[i // 2, (i % 2)+2].axis('off')\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.subplots_adjust(top=0.88)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "They look quite similar, right?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's divide the data set into train and validation to check the quality \n",
    "\n",
    "train_df, valid_df = train_test_split(data_df, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.shape, valid_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = FaceDataset(train_df, train_transform)\n",
    "valid_dataset = FaceDataset(valid_df, valid_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                           batch_size=64,\n",
    "                                           shuffle=True,\n",
    "                                           pin_memory=True,\n",
    "                                           num_workers=2)\n",
    "\n",
    "valid_loader = torch.utils.data.DataLoader(dataset=valid_dataset,\n",
    "                                           batch_size=64,\n",
    "                                           # shuffle=True,\n",
    "                                           pin_memory=True,\n",
    "                                           num_workers=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great, now let's write a couple of helper functions for visualization and training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(train_history, val_history, title='loss'):\n",
    "    plt.figure()\n",
    "    plt.title('{}'.format(title))\n",
    "    plt.plot(train_history, label='train', zorder=1)\n",
    "    \n",
    "    points = np.array(val_history)\n",
    "    steps = list(range(0, len(train_history) + 1, int(len(train_history) / len(val_history))))[1:]\n",
    "    \n",
    "    plt.scatter(steps, val_history, marker='+', s=180, c='orange', label='val', zorder=2)\n",
    "    plt.xlabel('train steps')\n",
    "    \n",
    "    plt.legend(loc='best')\n",
    "    plt.grid()\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, criterion, optimizer, train_dataloader, test_dataloader, NUM_EPOCH=15):\n",
    "    train_loss_log = []\n",
    "    val_loss_log = []\n",
    "    \n",
    "    train_acc_log = []\n",
    "    val_acc_log = []\n",
    "    \n",
    "    for epoch in tqdm(range(NUM_EPOCH)):\n",
    "        print(epoch)\n",
    "        model.train()\n",
    "        train_loss = 0.\n",
    "        train_size = 0\n",
    "        \n",
    "        train_pred = 0.\n",
    "\n",
    "        for imgs, labels in train_dataloader:\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            imgs = imgs.cuda()\n",
    "            labels = labels.cuda()\n",
    "\n",
    "            y_pred = model(imgs)\n",
    "\n",
    "            loss = criterion(y_pred, labels)\n",
    "            loss.backward()\n",
    "            \n",
    "            train_loss += loss.item()\n",
    "            train_size += y_pred.size(0)\n",
    "            train_loss_log.append(loss.data / y_pred.size(0))\n",
    "            \n",
    "            train_pred += (y_pred.argmax(1) == labels).sum()\n",
    "\n",
    "            optimizer.step()\n",
    "        \n",
    "        train_acc_log.append(train_pred / train_size)\n",
    "\n",
    "        val_loss = 0.\n",
    "        val_size = 0\n",
    "        \n",
    "        val_pred = 0.\n",
    "        \n",
    "        model.eval()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for imgs, labels in test_dataloader:\n",
    "                \n",
    "                imgs = imgs.cuda()\n",
    "                labels = labels.cuda()\n",
    "                \n",
    "                pred = model(imgs)\n",
    "                loss = criterion(pred, labels)\n",
    "                \n",
    "                val_loss += loss.item()\n",
    "                val_size += pred.size(0)\n",
    "                \n",
    "                val_pred += (pred.argmax(1) == labels).sum()\n",
    "\n",
    "        val_loss_log.append(val_loss / val_size)\n",
    "        val_acc_log.append(val_pred / val_size)\n",
    "\n",
    "        clear_output()\n",
    "        plot_history(train_loss_log, val_loss_log, 'loss')\n",
    "\n",
    "        print('Train loss:', (train_loss / train_size)*100)\n",
    "        print('Val loss:', (val_loss / val_size)*100)\n",
    "        print('Train acc:', (train_pred / train_size)*100)\n",
    "        print('Val acc:', (val_pred / val_size)*100)\n",
    "        \n",
    "    return train_loss_log, train_acc_log, val_loss_log, val_acc_log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model\n",
    "That's it, let's move on to training the model itself. Let's use a pre-trained ResNet and replace its classifier, and then we will train only it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-11T16:10:44.881393Z",
     "iopub.status.busy": "2021-06-11T16:10:44.881027Z",
     "iopub.status.idle": "2021-06-11T16:10:51.905792Z",
     "shell.execute_reply": "2021-06-11T16:10:51.904954Z",
     "shell.execute_reply.started": "2021-06-11T16:10:44.881357Z"
    }
   },
   "outputs": [],
   "source": [
    "# We upload the model\n",
    "model = models.resnet18(pretrained=True)\n",
    "model.fc = nn.Linear(512, 2)\n",
    "\n",
    "model = model.cuda()\n",
    "criterion = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.fc.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss_log, train_acc_log, val_loss_log, val_acc_log = train(model, \n",
    "                                                                 criterion, \n",
    "                                                                 optimizer, \n",
    "                                                                 train_loader, \n",
    "                                                                 valid_loader, \n",
    "                                                                 15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's look at the metrics of our final model for validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "valid_predicts = []\n",
    "\n",
    "for imgs, _ in tqdm(valid_loader):\n",
    "    \n",
    "    imgs = imgs.cuda()\n",
    "    pred = model(imgs)\n",
    "    \n",
    "    valid_predicts.append(pred.softmax(dim=1)[:, 1].cpu().detach().numpy()) # argmax(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_predicts = np.concatenate(valid_predicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_df['pred'] = valid_predicts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's calculate accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_acc = (valid_df['label'].values == (valid_df['pred'].values >= 0.5)*1).mean()\n",
    "print(f\"Validation accuracy = {val_acc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now roc-auc as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score, roc_curve, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_rocauc = roc_auc_score(valid_df['label'].values, valid_df['pred'].values)\n",
    "print(f\"Validation ROC-AUC = {val_rocauc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, threshold = roc_curve(y_true=valid_df['label'].values, \n",
    "                                        y_score=valid_df['pred'].values, \n",
    "                                        pos_label=1)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "plt.title('ROC-AUC curve')\n",
    "plt.plot(fpr, tpr, c='b', label='AUC = '+str(np.round(roc_auc,3)))\n",
    "plt.xlabel('False PR', fontsize=15)\n",
    "plt.ylabel('True PR', fontsize=15)\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks good!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's predict for the test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_paths = glob.glob(\"../input/data256faces/data256/test/*.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_names = [t_path.split('/')[-1] for t_path in test_paths]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.DataFrame(test_names, columns=['name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestFaceDataset(Dataset):\n",
    "    def __init__(self, data_df, transform=None):\n",
    "        self.data_df = data_df\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_name = self.data_df.iloc[idx]['name']\n",
    "        \n",
    "        image = cv2.imread(f\"../input/data256faces/data256/test/{image_name}\")\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        image = Image.fromarray(image)\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return image\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = TestFaceDataset(test_df, valid_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
    "                                           batch_size=64,\n",
    "                                           # shuffle=True,\n",
    "                                           pin_memory=True,\n",
    "                                           num_workers=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We predict the result using our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "predicts = []\n",
    "\n",
    "for imgs in tqdm(test_loader):\n",
    "    \n",
    "    imgs = imgs.cuda()\n",
    "    pred = model(imgs)\n",
    "    \n",
    "    predicts.append(pred.softmax(dim=1)[:, 1].cpu().detach().numpy()) # argmax(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicts = np.concatenate(predicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit_df = pd.DataFrame([[name, pred] for name, pred in zip(test_names, predicts)], columns=['name', 'pred'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit_df = submit_df.sort_values(['name'])\n",
    "submit_df.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We get the final file, 'submit.csv', sorted by name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit_df.to_csv(\"submit.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
